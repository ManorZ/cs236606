{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenMP* Device Parallelism (C/C++)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sections\n",
    "- [Learning Objectives](#Learning-Objectives)\n",
    "- [Device Parallelism](#Device-Parallelism)\n",
    "- [GPU Architecture](#GPU-Architecture)\n",
    "- [\"Normal\" OpenMP constructs](#\"Normal\"-OpenMP-constructs)\n",
    "- [League of Teams](#League-of-Teams)\n",
    "- [Worksharing with Teams](#Worksharing-with-Teams)\n",
    "- [Host Device Concurrency](#Host-Device-Concurrency)\n",
    "- _Code:_ [Lab Exercise: OpenMP Device Parallelism](#Lab-Exercise:-OpenMP-Device-Parallelism)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Explain basic GPU Architecture \n",
    "* Be able to use OpenMP offload worksharing constructs to fully utilize the GPU\n",
    "\n",
    "### Prerequisites\n",
    "Basic understanding of OpenMP constructs are assumed for this module. You also should have already went through the  [Introduction to OpenMP Offload module](../intro/intro.ipynb) and [Managing Device Data module](../datatransfer/datatransfer.ipynb), where the basics of using the Jupyter notebooks with the Intel® DevCloud and an introduction to the OpenMP `target` and `target data` constructs were discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Device Parallelism\n",
    "As we've discussed in the previous modules, the OpenMP `target` construct transfers the control flow to the target device. However, the transfer of control is sequential and synchronous.\n",
    "\n",
    "In OpenMP, offload and parallelism are separate, so programmers need to explicitly create parallel regions on the target device. In theory, constructs that create parallelism on offload devices can be combined with any OpenMP construct, but in practice, only a subset of OpenMP constructs are useful for the target device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Architecture\n",
    "Before diving into OpenMP parallelism constructs for target divices, let's first examine Intel® GPU architecture.\n",
    "\n",
    "<img src=\"Assets/GPU_Arch.png\">\n",
    "\n",
    "Intel® GPUs contain 1 or more slices. Each slice is composed of several Subslices (also called GPU cores). Each subslice contain multiple EUs (likely 8 or more), has it's own thread dispatcher unit, instruction cache, share local memory, and other resources. EUs are compute processors that drive the SIMD ALUs.\n",
    "\n",
    "The following table displays how the OpenMP concepts of League, Team, Thread, and SIMD are mapped to GPU hardware.\n",
    "\n",
    "|OpenMP | GPU Hardware |\n",
    "|:----:|:----|\n",
    "|SIMD | SIMD Lane (Channel)|\n",
    "|Thread | SIMD Thread mapped to an EU |\n",
    "|Team | Group of threads mapped to a Subslice |\n",
    "|League | Multiple Teams mapped to a GPU |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Normal\" OpenMP constructs\n",
    "OpenMP GPU offload support all \"normal\" OpenMP constructs such as `parallel`, `for`, `barrier`, `sections`, `tasks`, etc. However, not every construct will be useful for the GPU. When using these constructs, the full threading model is only supported with in a subslice, this is because there's no synchronization among subslices, and there's no coherence and memory fence among subslices' L1 caches.\n",
    "\n",
    "Let's examine the following example.\n",
    "```c\n",
    "void saxpy(float a, float* x, float* y, int sz) {\n",
    "    #pragma omp target map(to:x[0:sz]) map(tofrom(y[0:sz])\n",
    "    #pragma omp parallel for simd\n",
    "    for (int i=0; i< sz; i++) {\n",
    "        y[i] = a * x[i] + y[i];\n",
    "    }\n",
    "}\n",
    "```\n",
    "Here, we use the `target` pragma to offload the execution to the GPU. We then use `parallel` to create a team of threads, `for` to distribute loop iterations to those threads, and `simd` to request iteration vectorization with SIMD instructions. However, due to the restrictions aforementioned, only one GPU subslice is utilized here, so the GPU would be significantly underutilized. In some cases, the compiler may deduce `team distribute` from `parallel for` and still use the entire GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## League of Teams\n",
    "To take advantage of multiple subslices, use the `teams` pragma to create multiple **master** threads for execution. When combined with the `parallel` pragma, these master threads become a league of thread teams. Becuase there's no synchronization across teams of threads, the teams could then be assigned to different GPU subslices.\n",
    "\n",
    "<img src=\"Assets/teams.JPG\">\n",
    "\n",
    "When using the `teams` construct, the number of teams created is implementation defined. Although, you may optionally specify an upper limit with the **num_teams** clause. The **thread_limit** clause of the `teams` pragma can be optionally used to limit the number of threads in each team.\n",
    "\n",
    "Example: `#pragma omp teams num_teams(8) thread_limit(16)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksharing with Teams\n",
    "After a league of teams is created by `teams`, use the `distribute` construct to distribute chunks of iterations of a loop across the different teams in the league. This is analogous to what the `for` construct does for `parallel` regions. The `distribute` pragma is associated with a loop nest inside a teams region.\n",
    "\n",
    "For nested loops, the **collapse** clause can be used to specify how many loops are associated with the `distribute` pragma. You may specify a **collapse** clause with a parameter value greater than 1 to collapse associated loops into one large loop.\n",
    "\n",
    "You can also use **dist_schedule** clause on the `distribute` construct to manually specify the chunk size that are distributed to master threads of each team. For example, `#pragma omp distribute dist_schedule(static, 512)` would create chunks of 512 iterations.\n",
    "\n",
    "### Example with Combined Constructs\n",
    "For convenience, OpenMP supports combined constructs for OpenMP offload. The code below shows how a single line can encompass all of the pragmas that we've discussed.\n",
    "```c\n",
    "void saxpy (float a, float *x, float *y, int sz) {\n",
    "    #pragma omp target teams distribute parallel for simd \\\n",
    "                map(to:x(0:sz)) map(tofrom(y(0:sz))\n",
    "    for (int i=0; i<sz; i++) {\n",
    "        y[i] = a*x[i] + y[i];\n",
    "    }\n",
    "}\n",
    "```\n",
    "When these constructs are used without additional clauses, the number of teams created, the number of threads created per team, and how loop iterations are distributed are all implementation defined.\n",
    "The following diagram breaks down the effects of each pragma in the previous example. Here, we assume that there are a total of 128 loop iterations and that 4 teams, and 4 threads per team are created by the implementation.\n",
    "\n",
    "1. The `omp target` pragma offloads the execution to device\n",
    "2. The `omp teams` pragma creates multiple master threads, 4 thread teams in this diagram.\n",
    "3. The `omp distribute` pragma distributes loop iterations to those 4 thread teams, 32 threads for each team shown.\n",
    "4. The `omp parallel` pragma creates a team of threads for each master thread (team), 4 threads created for each team shown.\n",
    "5. The `omp for` pragma distributes the 32 iterations to each of the 4 threads.\n",
    "6. The `omp simd` pragma specifies that multiple iterations of the loop can be executed using SIMD instructions.\n",
    "\n",
    "<img src=\"Assets/distribute.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host Device Concurrency\n",
    "\n",
    "When a target region is encountered, a host task is generated, which synchronizes the CPU and target device. OpenMP uses tasking to manage execution and dependencies. Add the `nowait` clause so the host does not need to wait for target region to complete.\n",
    "\n",
    "```c\n",
    "#pragma omp target nowait\n",
    "```\n",
    "\n",
    "Using a `nowait` clause with a `target` construct allows for asynchronous offloading, allowing the host device to continue execution. One way to synchronize a target region back with the host device is by using the `taskwait` construct, which will wait until all tasks complete.\n",
    "\n",
    "In the following example, the for loop is offloaded to the target device, while the host device continues exectution and performs other work. After both the device and host complete finish, the host device will continue execution. \n",
    "\n",
    "```c\n",
    "#pragma omp target map(to:b,c,d) map(from:a) nowait\n",
    "{\n",
    "    #pragma omp teams distribute parallel for simd\n",
    "    for (i=0; i<500; i++) {\n",
    "        a[i] = b[i] * c + d;\n",
    "    }\n",
    "}\n",
    "\n",
    "#pragma omp task\n",
    "    other_work();\n",
    "\n",
    "#pragma omp taskwait //Synchronization\n",
    "    a0 = a[0];\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Exercise: OpenMP Device Parallelism\n",
    "In this exercise, we will practice using the offload worksharing constructs on the saxpy function that we've already worked with in the previous modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m//=\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m//\u001b[0m \u001b[0mCopyright\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m©\u001b[0m \u001b[0;36m2020\u001b[0m \u001b[0mIntel\u001b[0m \u001b[0mCorporation\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m//\u001b[0m \u001b[0mSPDX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mLicense\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mIdentifier\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMIT\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m//\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;31m#include <omp.h>\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;31m#include <stdio.h>\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0mconstexpr\u001b[0m \u001b[0mint\u001b[0m \u001b[0mARRAY_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0mconstexpr\u001b[0m \u001b[0mint\u001b[0m \u001b[0mNUM_BLOCKS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0mint\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m \u001b[0margc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_teams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mdouble\u001b[0m \u001b[0mtstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtstop\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mfloat\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mARRAY_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mARRAY_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mfloat\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mfloat\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mint\u001b[0m \u001b[0mcorrect_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;34m//\u001b[0m \u001b[0mInitialize\u001b[0m \u001b[0msome\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mARRAY_SIZE\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mtstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_get_wtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;31m#include \"lab/saxpy_func_parallel.cpp\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mtstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_get_wtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of OpenMP Devices Available: %d\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momp_get_num_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running on %s.\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cpu\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m \u001b[0;34m\"CPU\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Work took %f seconds.\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of Teams Created: %d\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_teams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mARRAY_SIZE\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mcorrect_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect Result at Element y[%d] : %f\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected: %f\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test: %s\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrect_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mARRAY_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m \u001b[0;34m\"PASSED!\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"Failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Optional, see the contents of main.cpp\n",
    "%pycat main.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, add OpenMP pragmas at the locations indicated to perform the following tasks.\n",
    "1. For the outer loop, use a **combined** construct to\n",
    "    1. Create NUM_BLOCKS of **master** threads, use the clause *num_teams(NUM_BLOCKS)*\n",
    "    2. Distribute the outer loop iterations to the varoius master threads.\n",
    "2. For the inner loop, use a combined construct to \n",
    "    1. Create a team of threads for each master thread.\n",
    "    2. Distribute inner loop iterations to those threads.\n",
    "    3. Signal that multiple loop iterations can be executed concurrently with SIMD instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lab/saxpy_func_parallel.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/saxpy_func_parallel.cpp\n",
    "#pragma omp target map(from: is_cpu) map(from:num_teams) map(to:x[0:ARRAY_SIZE]) map(tofrom:y[0:ARRAY_SIZE])\n",
    "{\n",
    "  // 1. Add pragma to create multiple master threads use clause num_teams(NUM_BLOCKS)\n",
    "  //    and distribute loop iterations to the various master threads.\n",
    "\n",
    "  for (ib = 0; ib < ARRAY_SIZE; ib += NUM_BLOCKS) {\n",
    "    if (ib == 0) {\n",
    "      // Test if target is the CPU Host or the GPU Device\n",
    "      is_cpu = omp_is_initial_device();\n",
    "      // Query number of teams created\n",
    "      num_teams = omp_get_num_teams();\n",
    "    }\n",
    "\n",
    "    // 2. Place the combined pragma here to create a team of threads for each master thread\n",
    "    //   Distribute iterations to those threads, and vectorize\n",
    "\n",
    "    for (i = ib; i < ib + NUM_BLOCKS; i++) {\n",
    "      y[i] = a * x[i] + y[i];\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compile and run the code by using the _run.sh_ script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m#!/bin/bash\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mintel\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moneapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msetvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnull\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mecho\u001b[0m \u001b[0;34m\"##\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m$\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhoami\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrunning\u001b[0m \u001b[0mOMP_Offload\u001b[0m \u001b[0mModule3\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mParallelism\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf90\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0mecho\u001b[0m \u001b[0;34m\"########## Compiling\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0micpx\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mqopenmp\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfopenmp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspir64\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpp\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mo\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m|\u001b[0m\u001b[0;34m|\u001b[0m \u001b[0mexit\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m$\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0mecho\u001b[0m \u001b[0;34m\"########## Executing\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0mcd\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0mecho\u001b[0m \u001b[0;34m\"########## Done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Optionally examine the run script by executing this cell.\n",
    "%pycat run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to run the program. Make sure you see the \"Passed!\" message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2114894.v-qsvr-1           run_serial.sh    u166450         04:16:34 R batch          \n",
      "2114895.v-qsvr-1           run_serial.sh    u166450         04:15:16 R batch          \n",
      "2115004.v-qsvr-1           ...ub-singleuser u166450         00:00:17 R jupyterhub     \n",
      "2116187.v-qsvr-1           run.sh           u166450                0 Q batch          \n",
      "\n",
      "Waiting for Output ███████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Thu 05 Jan 2023 03:00:58 AM PST\n",
      "#    Job ID:           2116187.v-qsvr-1.aidevcloud\n",
      "#      User:           u166450\n",
      "# Resources:           cput=75:00:00,neednodes=1:gpu:ppn=2,nodes=1:gpu:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "## u166450 is running OMP_Offload Module3 -- Parallelism - 1 of 1 main.cpp/main.f90\n",
      "########## Compiling\n",
      "########## Executing\n",
      "Number of OpenMP Devices Available: 1\n",
      "Running on GPU.\n",
      "Work took 0.662683 seconds.\n",
      "Number of Teams Created: 1\n",
      "Test: PASSED!\n",
      "########## Done\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2116187.v-qsvr-1.aidevcloud\n",
      "# Date: Thu 05 Jan 2023 03:01:17 AM PST\n",
      "########################################################################\n",
      "\n",
      "Libomptarget --> Init target library!\n",
      "Libomptarget --> Initialized OMPT\n",
      "Libomptarget --> Loading RTLs...\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.level0.so'...\n",
      "Target LEVEL0 RTL --> Init Level0 plugin!\n",
      "Target LEVEL0 RTL --> omp_get_thread_limit() returned 2147483647\n",
      "Target LEVEL0 RTL --> omp_get_max_teams() returned 0\n",
      "Libomptarget --> Successfully loaded library 'libomptarget.rtl.level0.so'!\n",
      "Target LEVEL0 RTL --> Looking for Level0 devices...\n",
      "Target LEVEL0 RTL --> Found a GPU device, Name = Intel(R) UHD Graphics [0x9a60]\n",
      "Target LEVEL0 RTL --> Found 1 root devices, 1 total devices.\n",
      "Target LEVEL0 RTL --> List of devices (DeviceID[.SubID[.CCSID]])\n",
      "Target LEVEL0 RTL --> -- 0\n",
      "Target LEVEL0 RTL --> Root Device Information\n",
      "Target LEVEL0 RTL --> Device 0\n",
      "Target LEVEL0 RTL --> -- Name                         : Intel(R) UHD Graphics [0x9a60]\n",
      "Target LEVEL0 RTL --> -- PCI ID                       : 0x9a60\n",
      "Target LEVEL0 RTL --> -- Number of total EUs          : 32\n",
      "Target LEVEL0 RTL --> -- Number of threads per EU     : 7\n",
      "Target LEVEL0 RTL --> -- EU SIMD width                : 8\n",
      "Target LEVEL0 RTL --> -- Number of EUs per subslice   : 16\n",
      "Target LEVEL0 RTL --> -- Number of subslices per slice: 2\n",
      "Target LEVEL0 RTL --> -- Number of slices             : 1\n",
      "Target LEVEL0 RTL --> -- Local memory size (bytes)    : 65536\n",
      "Target LEVEL0 RTL --> -- Global memory size (bytes)   : 26554851328\n",
      "Target LEVEL0 RTL --> -- Cache size (bytes)           : 524288\n",
      "Target LEVEL0 RTL --> -- Max clock frequency (MHz)    : 1450\n",
      "Target LEVEL0 RTL --> Driver API version is 10003\n",
      "Target LEVEL0 RTL --> Interop property IDs, Names, Descriptions\n",
      "Target LEVEL0 RTL --> -- 0, device_num_eus, intptr_t, total number of EUs\n",
      "Target LEVEL0 RTL --> -- 1, device_num_threads_per_eu, intptr_t, number of threads per EU\n",
      "Target LEVEL0 RTL --> -- 2, device_eu_simd_width, intptr_t, physical EU simd width\n",
      "Target LEVEL0 RTL --> -- 3, device_num_eus_per_subslice, intptr_t, number of EUs per sub-slice\n",
      "Target LEVEL0 RTL --> -- 4, device_num_subslices_per_slice, intptr_t, number of sub-slices per slice\n",
      "Target LEVEL0 RTL --> -- 5, device_num_slices, intptr_t, number of slices\n",
      "Target LEVEL0 RTL --> -- 6, device_local_mem_size, intptr_t, local memory size in bytes\n",
      "Target LEVEL0 RTL --> -- 7, device_global_mem_size, intptr_t, global memory size in bytes\n",
      "Target LEVEL0 RTL --> -- 8, device_global_mem_cache_size, intptr_t, global memory cache size in bytes\n",
      "Target LEVEL0 RTL --> -- 9, device_max_clock_frequency, intptr_t, max clock frequency in MHz\n",
      "Target LEVEL0 RTL --> Found driver extensions:\n",
      "Target LEVEL0 RTL --> -- ZE_extension_float_atomics\n",
      "Target LEVEL0 RTL --> -- ZE_experimental_relaxed_allocation_limits\n",
      "Target LEVEL0 RTL --> -- ZE_experimental_module_program\n",
      "Target LEVEL0 RTL --> -- ZE_experimental_scheduling_hints\n",
      "Target LEVEL0 RTL --> -- ZE_experimental_global_offset\n",
      "Target LEVEL0 RTL --> -- ZE_extension_pci_properties\n",
      "Target LEVEL0 RTL --> -- ZE_extension_memory_compression_hints\n",
      "Target LEVEL0 RTL --> -- ZE_extension_memory_free_policies\n",
      "Target LEVEL0 RTL --> -- ZE_extension_device_memory_properties\n",
      "Target LEVEL0 RTL --> -- ZE_extension_raytracing\n",
      "Target LEVEL0 RTL --> -- ZE_experimental_power_saving_hint\n",
      "Target LEVEL0 RTL --> -- ZE_extension_cache_reservation\n",
      "Target LEVEL0 RTL --> Returning 1 top-level devices\n",
      "Libomptarget --> Registering RTL libomptarget.rtl.level0.so supporting 1 devices!\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_alloc_base\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_alloc_managed\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_realloc\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_aligned_alloc\n",
      "Libomptarget --> Optional interface: __tgt_rtl_register_host_pointer\n",
      "Libomptarget --> Optional interface: __tgt_rtl_unregister_host_pointer\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_context_handle\n",
      "Libomptarget --> Optional interface: __tgt_rtl_init_ompt\n",
      "Libomptarget --> Optional interface: __tgt_rtl_requires_mapping\n",
      "Libomptarget --> Optional interface: __tgt_rtl_push_subdevice\n",
      "Libomptarget --> Optional interface: __tgt_rtl_pop_subdevice\n",
      "Libomptarget --> Optional interface: __tgt_rtl_add_build_options\n",
      "Libomptarget --> Optional interface: __tgt_rtl_is_supported_device\n",
      "Libomptarget --> Optional interface: __tgt_rtl_create_interop\n",
      "Libomptarget --> Optional interface: __tgt_rtl_release_interop\n",
      "Libomptarget --> Optional interface: __tgt_rtl_use_interop\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_num_interop_properties\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_interop_property_value\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_interop_property_info\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_interop_rc_desc\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_num_sub_devices\n",
      "Libomptarget --> Optional interface: __tgt_rtl_is_accessible_addr_range\n",
      "Libomptarget --> Optional interface: __tgt_rtl_notify_indirect_access\n",
      "Libomptarget --> Optional interface: __tgt_rtl_is_private_arg_on_host\n",
      "Libomptarget --> Optional interface: __tgt_rtl_command_batch_begin\n",
      "Libomptarget --> Optional interface: __tgt_rtl_command_batch_end\n",
      "Libomptarget --> Optional interface: __tgt_rtl_kernel_batch_begin\n",
      "Libomptarget --> Optional interface: __tgt_rtl_kernel_batch_end\n",
      "Libomptarget --> Optional interface: __tgt_rtl_set_function_ptr_map\n",
      "Libomptarget --> Optional interface: __tgt_rtl_alloc_per_hw_thread_scratch\n",
      "Libomptarget --> Optional interface: __tgt_rtl_free_per_hw_thread_scratch\n",
      "Libomptarget --> Optional interface: __tgt_rtl_run_target_team_nd_region\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_device_info\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_aligned_alloc_shared\n",
      "Libomptarget --> Optional interface: __tgt_rtl_prefetch_shared_mem\n",
      "Target LEVEL0 RTL --> Initialized OMPT\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.opencl.so'...\n",
      "Target OPENCL RTL --> Init OpenCL plugin!\n",
      "Target OPENCL RTL --> omp_get_thread_limit() returned 2147483647\n",
      "Target OPENCL RTL --> omp_get_max_teams() returned 0\n",
      "Target OPENCL RTL --> Target device type is set to GPU\n",
      "Libomptarget --> Successfully loaded library 'libomptarget.rtl.opencl.so'!\n",
      "Target OPENCL RTL --> Start initializing OpenCL\n",
      "Target OPENCL RTL --> Platform OpenCL 3.0  has 1 Devices\n",
      "Target OPENCL RTL --> Extension clGetMemAllocInfoINTEL is found.\n",
      "Target OPENCL RTL --> Extension clHostMemAllocINTEL is found.\n",
      "Target OPENCL RTL --> Extension clDeviceMemAllocINTEL is found.\n",
      "Target OPENCL RTL --> Extension clSharedMemAllocINTEL is found.\n",
      "Target OPENCL RTL --> Extension clMemFreeINTEL is found.\n",
      "Target OPENCL RTL --> Extension clSetKernelArgMemPointerINTEL is found.\n",
      "Target OPENCL RTL --> Extension clEnqueueMemcpyINTEL is found.\n",
      "Target OPENCL RTL --> Extension clSetProgramSpecializationConstant is found.\n",
      "Target OPENCL RTL --> Extension clGetDeviceGlobalVariablePointerINTEL is found.\n",
      "Target OPENCL RTL --> Extension clGetKernelSuggestedLocalWorkSizeINTEL is found.\n",
      "Target OPENCL RTL --> Warning: Extension clGitsIndirectAllocationOffsets is not found.\n",
      "Target OPENCL RTL --> Device 0: Intel(R) UHD Graphics [0x9a60]\n",
      "Target OPENCL RTL --> Number of execution units on the device is 32\n",
      "Target OPENCL RTL --> Maximum work group size for the device is 512\n",
      "Target OPENCL RTL --> Maximum memory allocation size is 4294959104\n",
      "Target OPENCL RTL --> Device local mem size: 65536\n",
      "Libomptarget --> Registering RTL libomptarget.rtl.opencl.so supporting 1 devices!\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_alloc_base\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_alloc_managed\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_realloc\n",
      "Libomptarget --> Optional interface: __tgt_rtl_data_aligned_alloc\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_device_name\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_context_handle\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_data_alloc_info\n",
      "Libomptarget --> Optional interface: __tgt_rtl_init_ompt\n",
      "Libomptarget --> Optional interface: __tgt_rtl_requires_mapping\n",
      "Libomptarget --> Optional interface: __tgt_rtl_manifest_data_for_region\n",
      "Libomptarget --> Optional interface: __tgt_rtl_add_build_options\n",
      "Libomptarget --> Optional interface: __tgt_rtl_is_supported_device\n",
      "Libomptarget --> Optional interface: __tgt_rtl_create_interop\n",
      "Libomptarget --> Optional interface: __tgt_rtl_release_interop\n",
      "Libomptarget --> Optional interface: __tgt_rtl_use_interop\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_num_interop_properties\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_interop_property_value\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_interop_property_info\n",
      "Libomptarget --> Optional interface: __tgt_rtl_get_interop_rc_desc\n",
      "Libomptarget --> Optional interface: __tgt_rtl_is_accessible_addr_range\n",
      "Libomptarget --> Optional interface: __tgt_rtl_notify_indirect_access\n",
      "Libomptarget --> Optional interface: __tgt_rtl_is_private_arg_on_host\n",
      "Libomptarget --> Optional interface: __tgt_rtl_set_function_ptr_map\n",
      "Libomptarget --> Optional interface: __tgt_rtl_alloc_per_hw_thread_scratch\n",
      "Libomptarget --> Optional interface: __tgt_rtl_free_per_hw_thread_scratch\n",
      "Libomptarget --> Optional interface: __tgt_rtl_run_target_team_nd_region\n",
      "Target OPENCL RTL --> Initialized OMPT\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.ppc64.so'...\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.ppc64.so': !\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.ppc64.so': libomptarget.rtl.ppc64.so: cannot open shared object file: No such file or directory!\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.x86_64.so'...\n",
      "Libomptarget --> Successfully loaded library 'libomptarget.rtl.x86_64.so'!\n",
      "Libomptarget --> Registering RTL libomptarget.rtl.x86_64.so supporting 4 devices!\n",
      "Libomptarget --> Optional interface: __tgt_rtl_requires_mapping\n",
      "Libomptarget --> Optional interface: __tgt_rtl_set_function_ptr_map\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.cuda.so'...\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.cuda.so': !\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.cuda.so': libomptarget.rtl.cuda.so: cannot open shared object file: No such file or directory!\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.aarch64.so'...\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.aarch64.so': !\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.aarch64.so': libomptarget.rtl.aarch64.so: cannot open shared object file: No such file or directory!\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.ve.so'...\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.ve.so': !\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.ve.so': libomptarget.rtl.ve.so: cannot open shared object file: No such file or directory!\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.amdgpu.so'...\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.amdgpu.so': !\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.amdgpu.so': libomptarget.rtl.amdgpu.so: cannot open shared object file: No such file or directory!\n",
      "Libomptarget --> Loading library 'libomptarget.rtl.rpc.so'...\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.rpc.so': !\n",
      "Libomptarget --> Unable to load library 'libomptarget.rtl.rpc.so': libomptarget.rtl.rpc.so: cannot open shared object file: No such file or directory!\n",
      "Libomptarget --> RTLs loaded!\n",
      "Target LEVEL0 RTL --> Target binary is a valid oneAPI OpenMP image.\n",
      "Libomptarget --> Image 0x0000000000402260 is compatible with RTL libomptarget.rtl.level0.so!\n",
      "Libomptarget --> RTL 0x0000000000ec5a20 has index 0!\n",
      "Libomptarget --> Registering image 0x0000000000402260 with RTL libomptarget.rtl.level0.so!\n",
      "Libomptarget --> Done registering entries!\n",
      "Libomptarget --> Entering target region with entry point 0x0000000000402120 and device Id 0\n",
      "Libomptarget --> Call to omp_get_num_devices returning 1\n",
      "Libomptarget --> Default TARGET OFFLOAD policy is now mandatory (devices were found)\n",
      "Libomptarget --> Call to omp_get_num_devices returning 1\n",
      "Libomptarget --> Call to omp_get_num_devices returning 1\n",
      "Libomptarget --> Call to omp_get_initial_device returning 1\n",
      "Libomptarget --> Checking whether device 0 is ready.\n",
      "Libomptarget --> Is the device 0 (local ID 0) initialized? 0\n",
      "Target LEVEL0 RTL --> Initialize requires flags to 1\n",
      "Target LEVEL0 RTL --> Allocated a device memory 0xffffd556aa7e0000\n",
      "Target LEVEL0 RTL --> Initialized device memory pool for device 0x00000000012eabd0: AllocUnit = 65536, AllocMax = 1048576, Capacity = 4, PoolSizeMax = 268435456\n",
      "Target LEVEL0 RTL --> Allocated a shared memory 0x000000000150c000\n",
      "Target LEVEL0 RTL --> Initialized shared memory pool for device 0x00000000012eabd0: AllocUnit = 65536, AllocMax = 8388608, Capacity = 4, PoolSizeMax = 268435456\n",
      "Target LEVEL0 RTL --> Initialized reduction scratch pool for device 0x00000000012eabd0: AllocMin = 65536, AllocMax = 268435456, PoolSizeMax = 8589934592\n",
      "Target LEVEL0 RTL --> Allocated a host memory 0x000000000130b000\n",
      "Target LEVEL0 RTL --> Initialized host memory pool for device 0x00000000012eabd0: AllocUnit = 65536, AllocMax = 1048576, Capacity = 4, PoolSizeMax = 268435456\n",
      "Target LEVEL0 RTL --> Created a command queue 0x0000000001256fd0 (Ordinal: 0, Index: 0) for device 0.\n",
      "Target LEVEL0 RTL --> Initialized Level0 device 0\n",
      "Libomptarget --> Device 0 is ready to use.\n",
      "Target LEVEL0 RTL --> Device 0: Loading binary from 0x0000000000402260\n",
      "Target LEVEL0 RTL --> Expecting to have 1 entries defined\n",
      "Target LEVEL0 RTL --> Base L0 module compilation options: -cl-std=CL2.0  \n",
      "Target LEVEL0 RTL --> Found a single section in the image\n",
      "Target LEVEL0 RTL --> Created module from image #0.\n",
      "Target LEVEL0 RTL --> Module link is not required\n",
      "Target LEVEL0 RTL --> Looking up device global variable '__omp_offloading_entries_table_size' of size 8 bytes on device 0.\n",
      "Target LEVEL0 RTL --> Global variable lookup succeeded (size: 8 bytes).\n",
      "Target LEVEL0 RTL --> Created a command list 0x00000000017d7df0 (Ordinal: 0) for device 0.\n",
      "Target LEVEL0 RTL --> Looking up device global variable '__omp_offloading_entries_table' of size 40 bytes on device 0.\n",
      "Target LEVEL0 RTL --> Global variable lookup succeeded (size: 40 bytes).\n",
      "Target LEVEL0 RTL --> Device offload table loaded:\n",
      "Target LEVEL0 RTL --> \t0:\t__omp_offloading_3c_595df9bc__Z4main_l1\n",
      "Target LEVEL0 RTL --> Looking up device global variable '__omp_offloading_3c_595df9bc__Z4main_l1_kernel_info' of unknown size on device 0.\n",
      "Target LEVEL0 RTL --> Global variable lookup succeeded (size: 88 bytes).\n",
      "Target LEVEL0 RTL --> Kernel 0: Entry = 0x0000000000402120, Name = __omp_offloading_3c_595df9bc__Z4main_l1, NumArgs = 7, Handle = 0x0000000001dc6200\n",
      "Target LEVEL0 RTL --> Looking up device global variable '__omp_spirv_program_data' of size 64 bytes on device 0.\n",
      "Target LEVEL0 RTL --> Global variable lookup succeeded (size: 64 bytes).\n",
      "Target LEVEL0 RTL --> Allocated a device memory 0xffffd556aa4f0000\n",
      "Target LEVEL0 RTL --> Allocated a device memory 0xffffd556aa4e0000\n",
      "Target LEVEL0 RTL --> New block allocation for device memory pool: base = 0xffffd556aa4e0000, size = 65536, pool size = 65536\n",
      "Target LEVEL0 RTL --> Allocated a device memory 0xffffd556aa4d0000\n",
      "Target LEVEL0 RTL --> New block allocation for device memory pool: base = 0xffffd556aa4d0000, size = 65536, pool size = 131072\n",
      "Target LEVEL0 RTL --> Allocated a device memory 0xffffd556aa4c0000\n",
      "Target LEVEL0 RTL --> New block allocation for device memory pool: base = 0xffffd556aa4c0000, size = 65536, pool size = 196608\n",
      "Libomptarget --> Entry  0: Base=0x00007ffe2217526c, Begin=0x00007ffe2217526c, Size=4, Type=0x22, Name=unknown\n",
      "Libomptarget --> Entry  1: Base=0x00007ffe22175268, Begin=0x00007ffe22175268, Size=4, Type=0x22, Name=unknown\n",
      "Libomptarget --> Entry  2: Base=0x00007ffe221752f0, Begin=0x00007ffe221752f0, Size=1024, Type=0x23, Name=unknown\n",
      "Libomptarget --> Entry  3: Base=0x00007ffe221756f0, Begin=0x00007ffe221756f0, Size=1024, Type=0x21, Name=unknown\n",
      "Libomptarget --> Entry  4: Base=0x0000000000000100, Begin=0x0000000000000100, Size=0, Type=0x120, Name=unknown\n",
      "Libomptarget --> Entry  5: Base=0x0000000000000000, Begin=0x0000000000000000, Size=0, Type=0x120, Name=unknown\n",
      "Libomptarget --> Entry  6: Base=0x000000003f800000, Begin=0x000000003f800000, Size=0, Type=0x120, Name=unknown\n",
      "Libomptarget --> loop trip count is 0.\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe2217526c, Size=4)...\n",
      "Target LEVEL0 RTL --> Ptr 0x00007ffe2217526c requires mapping\n",
      "Target LEVEL0 RTL --> Allocated a shared memory 0x0000000001d69000\n",
      "Target LEVEL0 RTL --> New block allocation for shared memory pool: base = 0x0000000001d69000, size = 65536, pool size = 65536\n",
      "Libomptarget --> Creating new map entry with HstPtrBegin=0x00007ffe2217526c, TgtPtrBegin=0x0000000001d69000, Size=4, DynRefCount=1, HoldRefCount=0, Name=unknown\n",
      "Libomptarget --> There are 4 bytes allocated at target address 0x0000000001d69000 - is new\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe22175268, Size=4)...\n",
      "Target LEVEL0 RTL --> Ptr 0x00007ffe22175268 requires mapping\n",
      "Libomptarget --> Creating new map entry with HstPtrBegin=0x00007ffe22175268, TgtPtrBegin=0x0000000001d69040, Size=4, DynRefCount=1, HoldRefCount=0, Name=unknown\n",
      "Libomptarget --> There are 4 bytes allocated at target address 0x0000000001d69040 - is new\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221752f0, Size=1024)...\n",
      "Target LEVEL0 RTL --> Ptr 0x00007ffe221752f0 requires mapping\n",
      "Target LEVEL0 RTL --> Allocated a shared memory 0x0000000001fe2000\n",
      "Target LEVEL0 RTL --> New block allocation for shared memory pool: base = 0x0000000001fe2000, size = 65536, pool size = 131072\n",
      "Libomptarget --> Creating new map entry with HstPtrBegin=0x00007ffe221752f0, TgtPtrBegin=0x0000000001fe2000, Size=1024, DynRefCount=1, HoldRefCount=0, Name=unknown\n",
      "Libomptarget --> Moving 1024 bytes (hst:0x00007ffe221752f0) -> (tgt:0x0000000001fe2000)\n",
      "Target LEVEL0 RTL --> Copied 1024 bytes (hst:0x00007ffe221752f0) -> (tgt:0x0000000001fe2000)\n",
      "Libomptarget --> There are 1024 bytes allocated at target address 0x0000000001fe2000 - is new\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221756f0, Size=1024)...\n",
      "Target LEVEL0 RTL --> Ptr 0x00007ffe221756f0 requires mapping\n",
      "Libomptarget --> Creating new map entry with HstPtrBegin=0x00007ffe221756f0, TgtPtrBegin=0x0000000001fe2400, Size=1024, DynRefCount=1, HoldRefCount=0, Name=unknown\n",
      "Libomptarget --> Moving 1024 bytes (hst:0x00007ffe221756f0) -> (tgt:0x0000000001fe2400)\n",
      "Target LEVEL0 RTL --> Copied 1024 bytes (hst:0x00007ffe221756f0) -> (tgt:0x0000000001fe2400)\n",
      "Libomptarget --> There are 1024 bytes allocated at target address 0x0000000001fe2400 - is new\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe2217526c, Size=4)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe2217526c, TgtPtrBegin=0x0000000001d69000, Size=4, DynRefCount=1 (update suppressed), HoldRefCount=0\n",
      "Libomptarget --> Obtained target argument (Begin: 0x0000000001d69000, Offset: 0) from host pointer 0x00007ffe2217526c\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe22175268, Size=4)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe22175268, TgtPtrBegin=0x0000000001d69040, Size=4, DynRefCount=1 (update suppressed), HoldRefCount=0\n",
      "Libomptarget --> Obtained target argument (Begin: 0x0000000001d69040, Offset: 0) from host pointer 0x00007ffe22175268\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221752f0, Size=1024)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe221752f0, TgtPtrBegin=0x0000000001fe2000, Size=1024, DynRefCount=1 (update suppressed), HoldRefCount=0\n",
      "Libomptarget --> Obtained target argument (Begin: 0x0000000001fe2000, Offset: 0) from host pointer 0x00007ffe221752f0\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221756f0, Size=1024)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe221756f0, TgtPtrBegin=0x0000000001fe2400, Size=1024, DynRefCount=1 (update suppressed), HoldRefCount=0\n",
      "Libomptarget --> Obtained target argument (Begin: 0x0000000001fe2400, Offset: 0) from host pointer 0x00007ffe221756f0\n",
      "Libomptarget --> Forwarding first-private value 0x0000000000000100 to the target construct\n",
      "Libomptarget --> Forwarding first-private value 0x0000000000000000 to the target construct\n",
      "Libomptarget --> Forwarding first-private value 0x000000003f800000 to the target construct\n",
      "Libomptarget --> Launching target execution __omp_offloading_3c_595df9bc__Z4main_l1 with pointer 0x0000000001309ba0 (index=0).\n",
      "Target LEVEL0 RTL --> Executing a kernel 0x0000000001309ba0...\n",
      "Target LEVEL0 RTL --> Assumed kernel SIMD width is 32\n",
      "Target LEVEL0 RTL --> Preferred team size is multiple of 64\n",
      "Target LEVEL0 RTL --> Max number of teams is set to 1 (num_teams clause or no teams construct)\n",
      "Target LEVEL0 RTL --> Team sizes = {64, 1, 1}\n",
      "Target LEVEL0 RTL --> Number of teams = {1, 1, 1}\n",
      "Target LEVEL0 RTL --> Kernel Pointer argument 0 (value: 0x0000000001d69000) was set successfully for device 0.\n",
      "Target LEVEL0 RTL --> Kernel Pointer argument 1 (value: 0x0000000001d69040) was set successfully for device 0.\n",
      "Target LEVEL0 RTL --> Kernel Pointer argument 2 (value: 0x0000000001fe2000) was set successfully for device 0.\n",
      "Target LEVEL0 RTL --> Kernel Pointer argument 3 (value: 0x0000000001fe2400) was set successfully for device 0.\n",
      "Target LEVEL0 RTL --> Kernel Scalar argument 4 (value: 0x0000000000000100) was set successfully for device 0.\n",
      "Target LEVEL0 RTL --> Kernel Scalar argument 5 (value: 0x0000000000000000) was set successfully for device 0.\n",
      "Target LEVEL0 RTL --> Kernel Scalar argument 6 (value: 0x000000003f800000) was set successfully for device 0.\n",
      "Target LEVEL0 RTL --> Setting indirect access flags 0x0000000000000006\n",
      "Target LEVEL0 RTL --> Submitted kernel 0x0000000001dc6200 to device 0\n",
      "Target LEVEL0 RTL --> Executed kernel entry 0x0000000001309ba0 on device 0\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221756f0, Size=1024)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe221756f0, TgtPtrBegin=0x0000000001fe2400, Size=1024, DynRefCount=0 (decremented, delayed deletion), HoldRefCount=0\n",
      "Libomptarget --> There are 1024 bytes allocated at target address 0x0000000001fe2400 - is last\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221752f0, Size=1024)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe221752f0, TgtPtrBegin=0x0000000001fe2000, Size=1024, DynRefCount=0 (decremented, delayed deletion), HoldRefCount=0\n",
      "Libomptarget --> There are 1024 bytes allocated at target address 0x0000000001fe2000 - is last\n",
      "Libomptarget --> Moving 1024 bytes (tgt:0x0000000001fe2000) -> (hst:0x00007ffe221752f0)\n",
      "Target LEVEL0 RTL --> Copied 1024 bytes (tgt:0x0000000001fe2000) -> (hst:0x00007ffe221752f0)\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe22175268, Size=4)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe22175268, TgtPtrBegin=0x0000000001d69040, Size=4, DynRefCount=0 (decremented, delayed deletion), HoldRefCount=0\n",
      "Libomptarget --> There are 4 bytes allocated at target address 0x0000000001d69040 - is last\n",
      "Libomptarget --> Moving 4 bytes (tgt:0x0000000001d69040) -> (hst:0x00007ffe22175268)\n",
      "Target LEVEL0 RTL --> Copied 4 bytes (tgt:0x0000000001d69040) -> (hst:0x00007ffe22175268)\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe2217526c, Size=4)...\n",
      "Libomptarget --> Mapping exists with HstPtrBegin=0x00007ffe2217526c, TgtPtrBegin=0x0000000001d69000, Size=4, DynRefCount=0 (decremented, delayed deletion), HoldRefCount=0\n",
      "Libomptarget --> There are 4 bytes allocated at target address 0x0000000001d69000 - is last\n",
      "Libomptarget --> Moving 4 bytes (tgt:0x0000000001d69000) -> (hst:0x00007ffe2217526c)\n",
      "Target LEVEL0 RTL --> Copied 4 bytes (tgt:0x0000000001d69000) -> (hst:0x00007ffe2217526c)\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221756f0, Size=1024)...\n",
      "Libomptarget --> Deleting tgt data 0x0000000001fe2400 of size 1024\n",
      "Libomptarget --> Removing map entry with HstPtrBegin=0x00007ffe221756f0, TgtPtrBegin=0x0000000001fe2400, Size=1024, Name=unknown\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe221752f0, Size=1024)...\n",
      "Libomptarget --> Deleting tgt data 0x0000000001fe2000 of size 1024\n",
      "Libomptarget --> Removing map entry with HstPtrBegin=0x00007ffe221752f0, TgtPtrBegin=0x0000000001fe2000, Size=1024, Name=unknown\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe22175268, Size=4)...\n",
      "Libomptarget --> Deleting tgt data 0x0000000001d69040 of size 4\n",
      "Libomptarget --> Removing map entry with HstPtrBegin=0x00007ffe22175268, TgtPtrBegin=0x0000000001d69040, Size=4, Name=unknown\n",
      "Libomptarget --> Looking up mapping(HstPtrBegin=0x00007ffe2217526c, Size=4)...\n",
      "Libomptarget --> Deleting tgt data 0x0000000001d69000 of size 4\n",
      "Libomptarget --> Removing map entry with HstPtrBegin=0x00007ffe2217526c, TgtPtrBegin=0x0000000001d69000, Size=4, Name=unknown\n",
      "Libomptarget --> Call to omp_get_num_devices returning 1\n",
      "Libomptarget --> Unloading target library!\n",
      "Libomptarget --> Unregistered image 0x0000000000402260 from RTL 0x0000000000ec5a20!\n",
      "Libomptarget --> Done unregistering images!\n",
      "Libomptarget --> Removing translation table for descriptor 0x0000000000402240\n",
      "Libomptarget --> Done unregistering library!\n",
      "Libomptarget --> Deinit target library!\n",
      "Target LEVEL0 RTL --> Deinit Level0 plugin!\n",
      "Target LEVEL0 RTL --> MemPool usage for host memory, device 0x00000000012eabd0\n",
      "Target LEVEL0 RTL --> -- Not used\n",
      "Target LEVEL0 RTL --> Memory usage for host memory, device 0x00000000012eabd0\n",
      "Target LEVEL0 RTL --> -- Not used\n",
      "Target LEVEL0 RTL --> Deleted device memory 0xffffd556aa4f0000 (Base: 0xffffd556aa4f0000, Size: 3145728)\n",
      "Target LEVEL0 RTL --> MemPool usage for shared memory, device 0x00000000012eabd0\n",
      "Target LEVEL0 RTL --> -- AllocMax=8(MB), Capacity=4, PoolSizeMax=256(MB)\n",
      "Target LEVEL0 RTL --> --                   :   NewAlloc      Reuse     Hit(%)\n",
      "Target LEVEL0 RTL --> -- Bucket[        64]:          1          1      50.00\n",
      "Target LEVEL0 RTL --> -- Bucket[      1024]:          1          1      50.00\n",
      "Target LEVEL0 RTL --> MemPool usage for device memory, device 0x00000000012eabd0\n",
      "Target LEVEL0 RTL --> -- AllocMax=1(MB), Capacity=4, PoolSizeMax=256(MB)\n",
      "Target LEVEL0 RTL --> --                   :   NewAlloc      Reuse     Hit(%)\n",
      "Target LEVEL0 RTL --> -- Bucket[        64]:          1          4      80.00\n",
      "Target LEVEL0 RTL --> -- Bucket[       512]:          1          0       0.00\n",
      "Target LEVEL0 RTL --> -- Bucket[      4096]:          1          0       0.00\n",
      "Target LEVEL0 RTL --> MemPool usage for device memory, device 0x00000000012eabd0\n",
      "Target LEVEL0 RTL --> -- Not used\n",
      "Target LEVEL0 RTL --> Memory usage for device memory, device 0x00000000012eabd0\n",
      "Target LEVEL0 RTL --> -- Allocator:       Native,         Pool\n",
      "Target LEVEL0 RTL --> -- Requested:      3342336,         4712\n",
      "Target LEVEL0 RTL --> -- Allocated:      3342336,         4928\n",
      "Target LEVEL0 RTL --> -- Freed    :      3342336,         4928\n",
      "Target LEVEL0 RTL --> -- InUse    :            0,            0\n",
      "Target LEVEL0 RTL --> -- PeakUse  :      3342336,         4928\n",
      "Target LEVEL0 RTL --> -- NumAllocs:            4,            7\n",
      "Target LEVEL0 RTL --> Memory usage for shared memory, device 0x00000000012eabd0\n",
      "Target LEVEL0 RTL --> -- Allocator:       Native,         Pool\n",
      "Target LEVEL0 RTL --> -- Requested:       131072,         2056\n",
      "Target LEVEL0 RTL --> -- Allocated:       131072,         2176\n",
      "Target LEVEL0 RTL --> -- Freed    :       131072,         2176\n",
      "Target LEVEL0 RTL --> -- InUse    :            0,            0\n",
      "Target LEVEL0 RTL --> -- PeakUse  :       131072,         2176\n",
      "Target LEVEL0 RTL --> -- NumAllocs:            2,            4\n",
      "Target LEVEL0 RTL --> Closed RTL successfully\n",
      "Target OPENCL RTL --> Deinit OpenCL plugin!\n",
      "Target OPENCL RTL --> Closed RTL successfully\n",
      "Job Completed in 27 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 q; chmod 755 run.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run.sh; else ./run.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_If the Jupyter cells are not responsive or if they error out when you compile the samples, please restart the Kernel and compile the samples again_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m#pragma omp target map(from: is_cpu) map(from:num_teams) map(to:x[0:ARRAY_SIZE]) map(tofrom:y[0:ARRAY_SIZE])\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;34m//\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0mAdd\u001b[0m \u001b[0mpragma\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mmaster\u001b[0m \u001b[0mthreads\u001b[0m \u001b[0muse\u001b[0m \u001b[0mclause\u001b[0m \u001b[0mnum_teams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_BLOCKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;34m//\u001b[0m    \u001b[0;32mand\u001b[0m \u001b[0mdistribute\u001b[0m \u001b[0mloop\u001b[0m \u001b[0miterations\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvarious\u001b[0m \u001b[0mmaster\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;31m#pragma omp teams distribute num_teams(NUM_BLOCKS)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mib\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mARRAY_SIZE\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mib\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mNUM_BLOCKS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mib\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;34m//\u001b[0m \u001b[0mTest\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCPU\u001b[0m \u001b[0mHost\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mDevice\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mis_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_is_initial_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0;34m//\u001b[0m \u001b[0mQuery\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mteams\u001b[0m \u001b[0mcreated\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0mnum_teams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_get_num_teams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m//\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0mPlace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcombined\u001b[0m \u001b[0mpragma\u001b[0m \u001b[0mhere\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mteam\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthreads\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mmaster\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m//\u001b[0m   \u001b[0mDistribute\u001b[0m \u001b[0miterations\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthose\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;31m#pragma omp parallel for simd\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mib\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mib\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNUM_BLOCKS\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m      \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pycat saxpy_func_parallel_solution.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this module, you have learned the following:\n",
    "* High-level overview of GPU architecture and how OpenMP constructs map to it.\n",
    "* Create multiple master threads that can be assigned to GPU subslices using the `teams` construct.\n",
    "* Distribute loop iterations to those master threads using the `distribute` construct.\n",
    "* Use the `teams` and `distribute` constructs combined with other OpenMP constructs for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><span style=\"color:green\"><h1>Survey</h1></span></body></html>\n",
    "\n",
    "[Tell us how we did in this module with a short survey. We will use your feedback to improve the quality and impact of these learning materials. Thanks!](https://intel.az1.qualtrics.com/jfe/form/SV_e3yrkDaDE7ZnKmN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><span style=\"color:Red\"><h1>Reset Notebook</h1></span></body></html>\n",
    "\n",
    "##### Should you be experiencing any issues with your notebook or just want to start fresh run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "button = widgets.Button(\n",
    "    description='Reset Notebook',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='This will update this notebook, overwriting any changes.',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "out = widgets.Output()\n",
    "def on_button_clicked(_):\n",
    "      # \"linking function with output\"\n",
    "      with out:\n",
    "          # what happens when we press the button\n",
    "          clear_output()\n",
    "          !rsync -a --size-only /data/oneapi_workshop/OpenMP_Offload/parallelism/ ~/OpenMP_Offload/parallelism\n",
    "          print('Notebook reset -- now click reload on browser.')\n",
    "# linking button and function together using a button's method\n",
    "button.on_click(on_button_clicked)\n",
    "# displaying button and its output together\n",
    "widgets.VBox([button,out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "@Intel Corporation | [\\*Trademark](https://www.intel.com/content/www/us/en/legal/trademarks.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
