{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HW3 Notebook\n",
    "\n",
    "## Submission instructions\n",
    "- **Publication Date: 5/1.**\n",
    "- **Submission Date: 22/1**.\n",
    "- **Submission in groups of up to 2 students (individually or in pairs).** \n",
    "- **Submission on the course website, in zip format including this directory with the relevant output, specifically:** \n",
    "  - the source files.\n",
    "  - this notebook (run_hw3.ipynb) after executing all the cells. \n",
    "  - output files of queued jobs that might be created during the execution. \n",
    "  \n",
    "- **Pay attention to keeping the timers wrapping the same work as the provided codes give.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fill the name and ID of the submitters:\n",
    "#### Student Name: Manor Zvi Stdudent ID: 204030720\n",
    "\n",
    "**Note:** If you submit in pairs, it is sufficient that only single student submit the assaignment on the course website. \\\n",
    "Remove one line if submitted individually, or keep it empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Vectorization and Compiler Optimizaiton\n",
    "**In this section you are required to work on a CPU node with Intel® Xeon® Scalable 6128 processors.** \\\n",
    "**Instruction Set Extension for this processor: Intel® SSE4.2, Intel® AVX, Intel® AVX2, Intel® AVX-512.** \\\n",
    "To submit a job to such a node, we use: \\\n",
    "```qsub -l nodes=1:gold6128:ppn=2``` (we ask for allocation of 1 compute node with the property of 'gold6128'). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 1: PI computation with icc optimizations (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/cs236606/HW3/HW3/icc_optimizaitons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the code using icc without any optimizations (-O0) and execute the code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137116.v-qsvr-1           ...ub-singleuser u177183         00:00:07 R jupyterhub     \n",
      "2137164.v-qsvr-1           no_opt.sh        u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ███████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Wed 18 Jan 2023 10:05:33 AM PST\n",
      "#    Job ID:           2137164.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 14.795541 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2137164.v-qsvr-1.aidevcloud\n",
      "# Date: Wed 18 Jan 2023 10:05:54 AM PST\n",
      "########################################################################\n",
      "\n",
      "Job Completed in 27 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 no_opt.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu no_opt.sh; else ./no_opt.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the execution time:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "execution time: 14.795541 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the code using icc with the default optimization level (-O2):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137116.v-qsvr-1           ...ub-singleuser u177183         00:00:22 R jupyterhub     \n",
      "2137186.v-qsvr-1           default_opt.sh   u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ██████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Wed 18 Jan 2023 10:32:34 AM PST\n",
      "#    Job ID:           2137186.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 2.446258 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2137186.v-qsvr-1.aidevcloud\n",
      "# Date: Wed 18 Jan 2023 10:32:43 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "Job Completed in 14 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 default_opt.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu default_opt.sh; else ./default_opt.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the execution time:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "execution time: 2.446258 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What optimizations were enabled?\n",
    "Was the main loop of the code **vectorized**? Explain. (use the compiler reports)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We've got 6.05X performance improved. Not bad!\n",
    "But not good either. This is because only 'regular' optimizations for speed were enabled (-O2). \n",
    "Main loop was not vectorized due to function call inside (remark #15543).\n",
    "The function f() is defined in another file, and the compilation was done without -ipo flag, hance the compiler couldn't vectorize the function.\n",
    "\n",
    "Let's now check that -ipo hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137116.v-qsvr-1           ...ub-singleuser u177183         00:00:22 R jupyterhub     \n",
      "2137185.v-qsvr-1           ...t_with_ipo.sh u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ███████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Wed 18 Jan 2023 10:32:05 AM PST\n",
      "#    Job ID:           2137185.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.590693 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2137185.v-qsvr-1.aidevcloud\n",
      "# Date: Wed 18 Jan 2023 10:32:12 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "Job Completed in 11 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 default_opt_with_ipo.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu default_opt_with_ipo.sh; else ./default_opt_with_ipo.sh; fi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "execution time: 0.590693 seconds."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we're talking! Now we've got 25.05X over baseline, that is 4.14X over -O2 without vectorization.\n",
    "But we know that our processor (Xeon Gold 6128) supports AVX512 which can process 8-width vectors on parallel (according to the lecture we have 2 of those per core, but I don't see it in the spec nor lscpu).\n",
    "So why we get 'only' 4X?\n",
    "Perhaps it is because we didn't specify the compiler explicitly to use AVX512, so it used AVX128 for example?\n",
    "\n",
    "It makes sense, because in bin_default_opt_with_ipo/ipo_out.optrpt, it says:\n",
    "remark #15305: vectorization support: vector length 2.\n",
    "\n",
    "Not sure what vector length means (it can be multiple things) but I suspect it refers to the width of the vector operator data-path.\n",
    "\n",
    "So let's give it a shot and add -xCORE-AVX512 to the compilation cmd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137116.v-qsvr-1           ...ub-singleuser u177183         00:00:26 R jupyterhub     \n",
      "2137206.v-qsvr-1           STDIN            u177183         00:00:00 R batch          \n",
      "2137208.v-qsvr-1           ...ith_avx512.sh u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output █████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Wed 18 Jan 2023 11:04:03 AM PST\n",
      "#    Job ID:           2137208.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.579214 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2137208.v-qsvr-1.aidevcloud\n",
      "# Date: Wed 18 Jan 2023 11:04:14 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "Job Completed in 21 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 default_opt_with_avx512.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu default_opt_with_avx512.sh; else ./default_opt_with_avx512.sh; fi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "execution time: 0.579214 seconds."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Not much different. \n",
    "\n",
    "But now bin_default_opt_with_avx512/ipo_out.optrpt says:\n",
    "remark #15305: vectorization support: vector length 4, so we've got wider.\n",
    "\n",
    "It also says:\n",
    "remark #26013: Compiler has chosen to target XMM/YMM vector. Try using -qopt-zmm-usage=high to override.\n",
    "\n",
    "So..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137116.v-qsvr-1           ...ub-singleuser u177183         00:00:31 R jupyterhub     \n",
      "2137206.v-qsvr-1           STDIN            u177183         00:00:00 R batch          \n",
      "2137225.v-qsvr-1           ..._zmm_usage.sh u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output █████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Wed 18 Jan 2023 11:18:44 AM PST\n",
      "#    Job ID:           2137225.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.347060 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2137225.v-qsvr-1.aidevcloud\n",
      "# Date: Wed 18 Jan 2023 11:18:51 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "Job Completed in 17 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 default_opt_with_avx512_with_high_zmm_usage.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu default_opt_with_avx512_with_high_zmm_usage.sh; else ./default_opt_with_avx512_with_high_zmm_usage.sh; fi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "execution time: 0.347060 seconds."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hopa! Now we've got 7.05X performance relative improvement. That's 42.63X over the baseline. Not too bad!\n",
    "\n",
    "Moreover, now it really utilize its AVX512 division. At least one of them:\n",
    "remark #15305: vectorization support: vector length 8.\n",
    "\n",
    "7.05X also makes sense from high-level analysis perspective:\n",
    "Since only the main loop can be speed-up by 8X, but there are other parts that couldn't, 8X is not reachable.\n",
    "Amdhal law gives us 8X as upper bound, in reality we are limited by the sequential parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit the compilation line in _ipo_simd_opt.sh_ to achieve better results.** \\\n",
    "Include **InterProcedural Optimizations (IPO)** and include different **SIMD instruction processor extensions** (try -xSSE4.2, -xAVX, -xCORE-AVX2, -xCORE-AVX512 or -xHost options. Consider adding -qopt-zmm-usage=high). You also can try using -O3 instead of -O2. Consider also including Profile-Guided Optimizations (PGO) that we mentioned in class. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HaHa Oops... I've already answered it partly.\n",
    "Sorry, I was too enthusiastic about the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137587.v-qsvr-1           ...ub-singleuser u177183         00:00:09 R jupyterhub     \n",
      "2137614.v-qsvr-1           ipo_simd_opt.sh  u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Thu 19 Jan 2023 01:53:13 AM PST\n",
      "#    Job ID:           2137614.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "---------------------\n",
      "Running O2 IPO AVX512\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.572032 seconds\n",
      "-----------------------------------------\n",
      "Running O2 IPO AVX512 with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.345517 seconds\n",
      "---------------------\n",
      "Running O2 IPO SSE4.2\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.591566 seconds\n",
      "-----------------------------------------\n",
      "Running O2 IPO SSE4.2 with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.583443 seconds\n",
      "---------------------\n",
      "Running O2 IPO AVX\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.564789 seconds\n",
      "-----------------------------------------\n",
      "Running O2 IPO AVX with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.562622 seconds\n",
      "---------------------\n",
      "Running O2 IPO AVX2\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.570559 seconds\n",
      "-----------------------------------------\n",
      "Running O2 IPO AVX2 with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.572570 seconds\n",
      "---------------------\n",
      "Running O2 IPO Host\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.571919 seconds\n",
      "-----------------------------------------\n",
      "Running O2 IPO Host with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.354297 seconds\n",
      "---------------------\n",
      "Running O3 IPO AVX512\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.576324 seconds\n",
      "-----------------------------------------\n",
      "Running O3 IPO AVX512 with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.345514 seconds\n",
      "---------------------\n",
      "Running O3 IPO SSE4.2\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.582562 seconds\n",
      "-----------------------------------------\n",
      "Running O3 IPO SSE4.2 with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.582442 seconds\n",
      "---------------------\n",
      "Running O3 IPO AVX\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.559717 seconds\n",
      "-----------------------------------------\n",
      "Running O3 IPO AVX with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.558286 seconds\n",
      "---------------------\n",
      "Running O3 IPO AVX2\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.571951 seconds\n",
      "-----------------------------------------\n",
      "Running O3 IPO AVX2 with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.578161 seconds\n",
      "---------------------\n",
      "Running O3 IPO Host\n",
      "---------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.579015 seconds\n",
      "-----------------------------------------\n",
      "Running O3 IPO Host with High ZMM Usage\n",
      "-----------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.343523 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2137614.v-qsvr-1.aidevcloud\n",
      "# Date: Thu 19 Jan 2023 01:53:37 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "Job Completed in 28 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 ipo_simd_opt.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu ipo_simd_opt.sh; else ./ipo_simd_opt.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the execution time:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Best execution time: 0.345517 seconds.\n",
    "\n",
    "This time was acheived with AVX512 with high zmm usage. -O3 didn't improve this result nor any other SIMD extension.\n",
    "\n",
    "From the documentation: xHost tells the compiler to generate instructions for the highest instruction set available on the compilation host processor.\n",
    "So it makes sense that the performace with -xHost is the same as with -xCORE-AVX512."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What optimizations were enabled?\n",
    "Was the main loop of the code **vectorized**? explain. (use the compiler reports)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All optimizations were enabled, with AVX512 8 lanes SIMD were enabled"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With PGO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137587.v-qsvr-1           ...ub-singleuser u177183         00:00:31 R jupyterhub     \n",
      "2138385.v-qsvr-1           ...md_pgo_opt.sh u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████████████████████████████████████████████████\n",
      "\n",
      "TimeOut 60 seconds: Job is still queued for execution, check for output file later (ipo_simd_pgo_opt.sh.o2138385)\n",
      "\n",
      " Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Thu 19 Jan 2023 03:41:08 AM PST\n",
      "#    Job ID:           2138385.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "--------------------------------------------------\n",
      "Running O3 IPO Host with High ZMM Usage to Collect\n",
      "--------------------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 2.717065 seconds\n",
      "---------------------------------------\n",
      "Running O3 IPO Host with High ZMM Usage\n",
      "---------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.391652 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2138385.v-qsvr-1.aidevcloud\n",
      "# Date: Thu 19 Jan 2023 03:41:21 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: warning #10187: PGOPTI instrumentation disables multifile optimizations\n",
      "icc: warning #10188: PGOPTI instrumentation disables IP optimizations\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "warning #30005: Existing ./pgopti.dpi will be overwritten.\n",
      "warning #30005: Existing ./pgopti.dpi will be overwritten.\n",
      "Job Completed in 60 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 ipo_simd_pgo_opt.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu ipo_simd_pgo_opt.sh; else ./ipo_simd_pgo_opt.sh; fi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It says: \n",
    "icc: warning #10187: PGOPTI instrumentation disables multifile optimizations\n",
    "\n",
    "So I guess IPO can't live in parallel with PGO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2137587.v-qsvr-1           ...ub-singleuser u177183         00:00:39 R jupyterhub     \n",
      "2138551.v-qsvr-1           ...md_pgo_opt.sh u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output █████████████████ Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Thu 19 Jan 2023 03:50:50 AM PST\n",
      "#    Job ID:           2138551.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "--------------------------------------------------\n",
      "Running O3 IPO Host with High ZMM Usage to Collect\n",
      "--------------------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 2.714652 seconds\n",
      "---------------------------------------\n",
      "Running O3 IPO Host with High ZMM Usage\n",
      "---------------------------------------\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 2.448272 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2138551.v-qsvr-1.aidevcloud\n",
      "# Date: Thu 19 Jan 2023 03:51:04 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "Job Completed in 17 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-cpu; chmod 755 ipo_simd_pgo_opt.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-cpu ipo_simd_pgo_opt.sh; else ./ipo_simd_pgo_opt.sh; fi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "But now the vectorization can't heppen since the function is defined in another file.\n",
    "\n",
    "So to conclude, IPO & PGO are counter-effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, we will use **OpenMP _simd_ pragmas** to enable vectorization without using IPO. \\\n",
    "**Edit _openmp_simd/pi.c_ and _openmp_simd/fx.c_ to enable vectorization of the main loop by adding openmp pragmas**.\n",
    "You can add the SIMD instruction processor extensions to the compiler as before, just avoid using -ipo. You also can try -O3 instead of -O2. \\\n",
    "Try to achieve the best vectorization possible with OpenMP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/cs236606/HW3/HW3/icc_optimizaitons/openmp_simd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2139155.v-qsvr-1           ...ub-singleuser u177183         00:01:52 R jupyterhub     \n",
      "2139407.v-qsvr-1           openmp_simd.sh   u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████████████████████████████████████████████████\n",
      "\n",
      "TimeOut 60 seconds: Job is still queued for execution, check for output file later (openmp_simd.sh.o2139407)\n",
      "\n",
      " Done⬇\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Thu 19 Jan 2023 08:13:49 AM PST\n",
      "#    Job ID:           2139407.v-qsvr-1.aidevcloud\n",
      "#      User:           u177183\n",
      "# Resources:           cput=75:00:00,neednodes=1:gold6128:ppn=2,nodes=1:gold6128:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "    pi is approximately : 3.141593 \n",
      "Elapsed time = 0.361307 seconds\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 2139407.v-qsvr-1.aidevcloud\n",
      "# Date: Thu 19 Jan 2023 08:13:56 AM PST\n",
      "########################################################################\n",
      "\n",
      "icc: remark #10397: optimization reports are generated in *.optrpt files in the output location\n",
      "Job Completed in 60 seconds.\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../../q-cpu; chmod 755 openmp_simd.sh;if [ -x \"$(command -v qsub)\" ]; then ./../../q-cpu openmp_simd.sh; else ./openmp_simd.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the execution time:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "execution time: 0.361307 seconds."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I tried varous combinations of #threads and simd/compilation flags.\n",
    "\n",
    "In all cases, the compiler didn't succeed to vectorize the function f when is was in another file.\n",
    "Even when I added extern for its decleration on pi.c or added the same #pragma there.\n",
    "So I copied it into the file pi.c\n",
    "\n",
    "But even then, for some reason, one thread simd (wihtout omp parallel for) had the best performance.\n",
    "Even when I tried to play with the thread affinity - proc_bind() - in order to distribute the work on all cores and by doing that use all AVX512 divisions, and not only one (I had a hypothesis that two hyper-threads on the same core share a single AVX512 division in hardware). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Offloading with OpenMP\n",
    "**In this section you are requested to work on a GPU node.** \\\n",
    "To submit a job to such a node, we use: \\\n",
    "```qsub -l nodes=1:gpu:ppn=2``` \n",
    "- You are encouraged to check the node specifications with _lscpu_, _cat /proc/cpuinfo_, _numactl --hardware_ and more. \n",
    "- When you implement an offloading version, run with _export LIBOMPTARGET_DEBUG=1_ to see some important details, including the available devices on the node and their specifications (amount of memory, number of compute units, etc).\n",
    "- It might be helpful to use the GPU Analysis with VTuneTM Profiler. Check the following links: \n",
    "- https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top/tools/vtune.html \n",
    "- https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/top/analyze-performance/accelerators-group/gpu-offload-analysis.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Heat Problem (30 points)\n",
    "The following code in _serial_heat.c_ implementes a finite difference method to solve the heat equation.\n",
    "1) **Run the given serial code** on a standard GPU node and report the run time. \n",
    "2) Edit _parallel_cpu_heat.c_ to implement an **OpenMP version with parallelism on CPU only (multi-core)**, and run on a standard GPU node.\n",
    "3) Edit _parallel_gpu_heat.c_ to implement an **OpenMP accelerated version with offloading to GPU device**, and run on the GPU node.\n",
    "\n",
    "- For the CPU and GPU versions try to provide your best implementations. \n",
    "- In this exercise we compile with -O2 but you can enhance compiler optimizations if it helps you achieve better performance (do not go crazy with compiler optimizatiosn here, this part is shaped mainly to exercise OpenMP GPU offloading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/cs236606/HW3/HW3/heat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 ../q-gpu; chmod 755 run_serial.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-gpu run_serial.sh; else ./run_serial.sh; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_serial.sh.o2143288-Error (L2norm): 3.488721E+09\n",
      "run_serial.sh.o2143288:Solve time (s): 24.611934\n",
      "run_serial.sh.o2143288-Total time (s): 29.484274\n",
      "--\n",
      "run_serial.sh.o2143339-Error (L2norm): 3.488721E+09\n",
      "run_serial.sh.o2143339:Solve time (s): 23.854402\n",
      "run_serial.sh.o2143339-Total time (s): 28.798660\n"
     ]
    }
   ],
   "source": [
    "! grep -H \"Solve time\" -A1 -B1 run_serial.sh.o*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 ../q-gpu; chmod 755 run_cpu.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-gpu run_cpu.sh; else ./run_cpu.sh; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_cpu.sh.o2143330-#pragma omp parallel for simd collapse(2) schedule(simd:static)\n",
      "run_cpu.sh.o2143330-Error (L2norm): 3.488721E+09\n",
      "run_cpu.sh.o2143330:Solve time (s): 396.125663\n",
      "run_cpu.sh.o2143330-Total time (s): 400.980976\n",
      "--\n",
      "run_cpu.sh.o2143336-for (int j = 0; j < n; ++j) { for (int i = 0; i < n; ++i) {\n",
      "run_cpu.sh.o2143336-Error (L2norm): 3.488721E+09\n",
      "run_cpu.sh.o2143336:Solve time (s): 56.613510\n",
      "run_cpu.sh.o2143336-Total time (s): 61.514467\n"
     ]
    }
   ],
   "source": [
    "! grep -H \"Solve time\" -A1 -B2 run_cpu.sh.o*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 ../q-gpu; chmod 755 run_gpu.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-gpu run_gpu.sh; else ./run_gpu.sh; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_gpu.sh.o2143300-#pragma omp loop collapse(2)\n",
      "run_gpu.sh.o2143300-Error (L2norm): 2.879362E+09\n",
      "run_gpu.sh.o2143300:Solve time (s): 19.285192\n",
      "run_gpu.sh.o2143300-Total time (s): 23.713873\n",
      "--\n",
      "run_gpu.sh.o2143313-#pragma omp loop collapse(2)\n",
      "run_gpu.sh.o2143313-Error (L2norm): 2.879362E+09\n",
      "run_gpu.sh.o2143313:Solve time (s): 19.075013\n",
      "run_gpu.sh.o2143313-Total time (s): 23.537265\n",
      "--\n",
      "run_gpu.sh.o2143317-#pragma omp parallel for simd collapse(2) schedule(simd:static)\n",
      "run_gpu.sh.o2143317-Error (L2norm): 2.879362E+09\n",
      "run_gpu.sh.o2143317:Solve time (s): 18.967389\n",
      "run_gpu.sh.o2143317-Total time (s): 23.388325\n",
      "--\n",
      "run_gpu.sh.o2143319-#pragma omp teams distribute parallel for simd collapse(2) schedule(simd:static)\n",
      "run_gpu.sh.o2143319-Error (L2norm): 2.879362E+09\n",
      "run_gpu.sh.o2143319:Solve time (s): 19.041946\n",
      "run_gpu.sh.o2143319-Total time (s): 23.507721\n"
     ]
    }
   ],
   "source": [
    "! grep -H \"Solve time\" -A1 -B2 run_gpu.sh.o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record the run times in the next cells respectively:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Serial Time: 23.854402 sec "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parallel CPU Time: 56.613510 sec"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parallel GPU Time: 18.967389 sec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are your conclusions from this work?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GPU offloading is a good solution for this workload.\n",
    "CPU offloading does not improve performance on this workload, probably do to the size of the problem (possibly also the memory layout which is not optimal).\n",
    "\n",
    "for the CPU parallel case, I tried varous threads count.\n",
    "I found that the optimal number is 8, altough the performance is still much worse than the serial case.\n",
    "\n",
    "8 makes sense since this is the number of cores per socket in the system we've got.\n",
    "\n",
    "I suspect that since the matrices involved are huge, and we've got 1 socket in this system (shared L3), all threads (spread across all cores) are threshing the L3 because of the size of the matrices.\n",
    "Moreover, the memory layout is quite bad (I improved it in the GPU Offloading code), and therfore also the L1 & L2 caches are constantly snoopying and syncing with each other. That also harm performance dramatically (as we saw in the 1st HW assignment).\n",
    "And lastly, in this implementation I opened and closed thread in each iteration (50 times). I could solve it as I've done in the previous assignment, but I didn't do it here. I think this also didn't help the performance in this case...\n",
    "\n",
    "P.S. I couldn't stop myself and fixed the layout issue also for the CPU parallel. 56.6 is after the fix. still worse than the serial version.\n",
    "\n",
    "IMPORTANT NOTE: qsub -l nodes=1:gpu:ppn=2 is not working. I'm attaching the error log for one run. To mitigate it, I used qsub -l nodes=1:gen9:ppn=2 instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Jacobi Problem (40 points)\n",
    "The following code in _serial_jacobi.c_ implementes the jacobi solver for solving a linear equation system.\n",
    "1) **Run the given serial code** on a standard GPU node and report the run time. \n",
    "2) Edit _parallel_gpu_jacobi.c_ (and the other files if needed) to implement an **OpenMP accelerated version with offloading to GPU device**, and run on the GPU node.\n",
    "\n",
    "- Try to provide your best implementation. \n",
    "- In this exercise we compile with -O2 but you can enhance compiler optimizations if it helps you achieve better performance (do not go crazy with compiler optimizatiosn here, this part is shaped mainly to exercise OpenMP GPU offloading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/cs236606/HW3/HW3/jacobi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2143346.v-qsvr-1           ...ub-singleuser u177183         00:00:01 R jupyterhub     \n",
      "2143348.v-qsvr-1           run_serial.sh    u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████████████████████████████████████████████████\n",
      "\n",
      "TimeOut 60 seconds: Job is still queued for execution, check for output file later (run_serial.sh.o2143348)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-gpu; chmod 755 run_serial.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-gpu run_serial.sh; else ./run_serial.sh; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_serial.sh.o2143348- ndim = 3000\n",
      "run_serial.sh.o2143348- Convergence = 0.000999529 with 14223 iterations and 51.900311 seconds\n",
      "run_serial.sh.o2143348:jacobi solver: err = 0.001000, solution checksum = 371.481995 \n"
     ]
    }
   ],
   "source": [
    "! grep -H \"jacobi solver:\" -B2 run_serial.sh.o*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has been submitted to Intel(R) DevCloud and will execute soon.\n",
      "\n",
      " If you do not see result in 60 seconds, please restart the Jupyter kernel:\n",
      " Kernel -> 'Restart Kernel and Clear All Outputs...' and then try again\n",
      "\n",
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "2143346.v-qsvr-1           ...ub-singleuser u177183         00:00:43 R jupyterhub     \n",
      "2143386.v-qsvr-1           run_gpu.sh       u177183                0 Q batch          \n",
      "\n",
      "Waiting for Output ████████████████████████████████████████████████████████████\n",
      "\n",
      "TimeOut 60 seconds: Job is still queued for execution, check for output file later (run_gpu.sh.o2143386)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! chmod 755 ../q-gpu; chmod 755 run_gpu.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q-gpu run_gpu.sh; else ./run_gpu.sh; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_gpu.sh.o2143377- ndim = 3000\n",
      "run_gpu.sh.o2143377- Convergence = 0.000999529 with 14223 iterations and 68.709557 seconds\n",
      "run_gpu.sh.o2143377:jacobi solver: err = 0.001000, solution checksum = 371.481995 \n",
      "--\n",
      "run_gpu.sh.o2143378- ndim = 3000\n",
      "run_gpu.sh.o2143378- Convergence = 0.000999529 with 14223 iterations and 36.448154 seconds\n",
      "run_gpu.sh.o2143378:jacobi solver: err = 0.001000, solution checksum = 371.481995 \n",
      "--\n",
      "run_gpu.sh.o2143383- ndim = 3000\n",
      "run_gpu.sh.o2143383- Convergence = 0.000999529 with 14223 iterations and 36.544998 seconds\n",
      "run_gpu.sh.o2143383:jacobi solver: err = 0.001000, solution checksum = 371.481995 \n",
      "--\n",
      "run_gpu.sh.o2143384- ndim = 3000\n",
      "run_gpu.sh.o2143384- Convergence = 0.000999529 with 14223 iterations and 36.572216 seconds\n",
      "run_gpu.sh.o2143384:jacobi solver: err = 0.001000, solution checksum = 371.481995 \n"
     ]
    }
   ],
   "source": [
    "! grep -H \"jacobi solver:\" -B2 run_gpu.sh.o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record the run times in the next cells respectively:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Serial Time: 51.900311 sec "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parallel GPU Time: 36.448154 sec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes:  \n",
    "1. Here also there was the same problem with 'gpu' node in devcloud.  \n",
    "So I changed it to 'gen9' instead.  \n",
    "But now it prints other errors, while at least succeed to run. Please see the error log attached to the submission.\n",
    "2. Also, the file you provided run_gpu.sh does not match the version if icx installed (probably this is the problem).  \n",
    "Using it as-is, I've got this error:  \n",
    "icx: error: cannot specify -o when generating multiple output files  \n",
    "So I remove the '-o' knob, and then ran the default output file, a.out.\n",
    "3. I used 2 main methods to improve performance:  \n",
    "    1. Remove divergent branches by masking\n",
    "    2. Better memory access efficiency by using col-major matrix instead of row-major.  \n",
    "        In that way, a lot of close items can be coalesced together to a single 'wide' memory access.\n",
    "4. No matter which combination of opemmp constructs & compiler knobs I used, I've got this warning:  \n",
    "warning: loop not vectorized: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]  \n",
    "But I think it refers to regular compiler attempts to vectorize and not the openmp vectorization on the device."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
